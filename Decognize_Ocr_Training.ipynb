{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8049db-f874-4bf1-9606-559fd6a4cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8366597a-607d-44ba-af0b-bb25f5500a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d82b777a-b0a2-4b5f-b4ea-7801b08adc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001.jpg</td>\n",
       "      <td>BALTHAZAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002.jpg</td>\n",
       "      <td>SIMON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003.jpg</td>\n",
       "      <td>BENES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004.jpg</td>\n",
       "      <td>LA LOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN_00005.jpg</td>\n",
       "      <td>DAPHNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330957</th>\n",
       "      <td>TRAIN_330957.jpg</td>\n",
       "      <td>LENNY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330958</th>\n",
       "      <td>TRAIN_330958.jpg</td>\n",
       "      <td>TIFFANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330959</th>\n",
       "      <td>TRAIN_330959.jpg</td>\n",
       "      <td>COUTINHO DESA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330960</th>\n",
       "      <td>TRAIN_330960.jpg</td>\n",
       "      <td>MOURAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330961</th>\n",
       "      <td>TRAIN_330961.jpg</td>\n",
       "      <td>HELOISE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330961 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id           text\n",
       "1        TRAIN_00001.jpg      BALTHAZAR\n",
       "2        TRAIN_00002.jpg          SIMON\n",
       "3        TRAIN_00003.jpg          BENES\n",
       "4        TRAIN_00004.jpg        LA LOVE\n",
       "5        TRAIN_00005.jpg         DAPHNE\n",
       "...                  ...            ...\n",
       "330957  TRAIN_330957.jpg          LENNY\n",
       "330958  TRAIN_330958.jpg        TIFFANY\n",
       "330959  TRAIN_330959.jpg  COUTINHO DESA\n",
       "330960  TRAIN_330960.jpg         MOURAD\n",
       "330961  TRAIN_330961.jpg        HELOISE\n",
       "\n",
       "[330961 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r\"\"\n",
    "data_csv = \"C:/Users/mahad/Desktop/fyp2/data/written_name_train_v2.csv\"\n",
    "df = pd.read_csv(data_csv, names=['id','text']).iloc[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865bb26b-3328-41cf-aee2-e593f43a95ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_327782.jpg</td>\n",
       "      <td>FRANCOIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_114977.jpg</td>\n",
       "      <td>BAILLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_197059.jpg</td>\n",
       "      <td>CHOPLIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_313671.jpg</td>\n",
       "      <td>LUCAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_324514.jpg</td>\n",
       "      <td>FLAVIEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33092</th>\n",
       "      <td>TRAIN_112186.jpg</td>\n",
       "      <td>HUGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33093</th>\n",
       "      <td>TRAIN_233515.jpg</td>\n",
       "      <td>HELASSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33094</th>\n",
       "      <td>TRAIN_270040.jpg</td>\n",
       "      <td>ILONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33095</th>\n",
       "      <td>TRAIN_214091.jpg</td>\n",
       "      <td>OSCAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33096</th>\n",
       "      <td>TRAIN_235570.jpg</td>\n",
       "      <td>ANGELE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33097 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id      text\n",
       "0      TRAIN_327782.jpg  FRANCOIS\n",
       "1      TRAIN_114977.jpg    BAILLY\n",
       "2      TRAIN_197059.jpg   CHOPLIN\n",
       "3      TRAIN_313671.jpg     LUCAS\n",
       "4      TRAIN_324514.jpg   FLAVIEN\n",
       "...                 ...       ...\n",
       "33092  TRAIN_112186.jpg      HUGO\n",
       "33093  TRAIN_233515.jpg   HELASSA\n",
       "33094  TRAIN_270040.jpg     ILONA\n",
       "33095  TRAIN_214091.jpg     OSCAR\n",
       "33096  TRAIN_235570.jpg    ANGELE\n",
       "\n",
       "[33097 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train,df_test = train_test_split(df,test_size = 0.1,random_state=0)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "sum([len(str(x).split()) for x in df_train['text']])/len(df_train)\n",
    "max([len(str(x).split()) for x in df_train['text']])\n",
    "sum([len(str(x).split()) for x in df_test['text']])/len(df_test)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aaa5c60-2820-4a76-8fa0-e2551a3ebcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter, ImageEnhance, ImageDraw\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def blur(img):\n",
    "    return img.filter(ImageFilter.BLUR)\n",
    "\n",
    "def gaussian_blur(img):\n",
    "    return img.filter(ImageFilter.GaussianBlur(radius=random.randint(1, 10)))\n",
    "\n",
    "def box_blur(img):\n",
    "    return img.filter(ImageFilter.BoxBlur(radius=random.randint(1, 10)))\n",
    "\n",
    "def contrast(img):\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    return enhancer.enhance(random.uniform(0.5, 1.5))  # Adjust contrast level\n",
    "\n",
    "def pixelate(img):\n",
    "    return img.resize((256, 256)).resize(img.size, Image.NEAREST)\n",
    "\n",
    "def rotate(img):\n",
    "    return img.rotate(random.randint(-45, 45))  # Rotate randomly between -45 and 45 degrees\n",
    "\n",
    "def perspective(img):\n",
    "    width, height = img.size\n",
    "    m = -0.5\n",
    "    xshift = abs(m) * width\n",
    "    new_width = width + int(round(xshift))\n",
    "    return img.transform((new_width, height), Image.AFFINE, (1, m, -xshift if m > 0 else 0, 0, 1, 0), Image.BICUBIC)\n",
    "\n",
    "def translate(img):\n",
    "    return img.transform(img.size, Image.AFFINE, (1, 0, random.randint(-50, 50), 0, 1, random.randint(-50, 50)))\n",
    "\n",
    "def noisy(noise_type, image):\n",
    "    if noise_type == \"gauss\":\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var ** 0.5\n",
    "        gauss = np.random.normal(mean, sigma, image.size)\n",
    "        noisy = np.array(image) + gauss\n",
    "        return Image.fromarray(noisy.astype('uint8'))\n",
    "    elif noise_type == \"s&p\":\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.array(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.size]\n",
    "        out[coords] = 255\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount * image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.size]\n",
    "        out[coords] = 0\n",
    "        return Image.fromarray(out.astype('uint8'))\n",
    "    elif noise_type == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return Image.fromarray(noisy.astype('uint8'))\n",
    "    elif noise_type == \"speckle\":\n",
    "        gauss = np.random.randn(*image.size)\n",
    "        noisy = np.array(image) + image * gauss\n",
    "        return Image.fromarray(noisy.astype('uint8'))\n",
    "\n",
    "def vertical_grid(img):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    line_width = random.randint(1, 3)\n",
    "    for y in range(0, img.size[1], line_width + random.randint(1, 3)):\n",
    "        draw.line([(0, y), (img.size[0], y)], fill='black', width=line_width)\n",
    "    return img\n",
    "\n",
    "def horizontal_grid(img):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    line_width = random.randint(1, 3)\n",
    "    for x in range(0, img.size[0], line_width + random.randint(1, 3)):\n",
    "        draw.line([(x, 0), (x, img.size[1])], fill='black', width=line_width)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f4f86c-0c9e-4e75-927d-db77cf47edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def show_image(pathStr):\n",
    "  img = Image.open(pathStr).convert(\"RGB\")\n",
    "  display(img)\n",
    "  return img\n",
    "\n",
    "def ocr_image(src_img):\n",
    "  pixel_values = processor(images=src_img, return_tensors=\"pt\").pixel_values\n",
    "  generated_ids = model.generate(pixel_values)\n",
    "  return processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce911882-7c8f-44b8-843f-759981e8ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ProcessorMixin, warnings\n",
    "\n",
    "class CustomOCRProcessor(ProcessorMixin):\n",
    "    # Define the attributes of the processor\n",
    "    attributes = [\"image_processor\", \"tokenizer\"]\n",
    "\n",
    "    # Define the default classes for image processor and tokenizer\n",
    "    image_processor_class = \"AutoImageProcessor\"\n",
    "    tokenizer_class = \"AutoTokenizer\"\n",
    "\n",
    "    def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n",
    "        # Check if the 'feature_extractor' argument is used (deprecated)\n",
    "        if \"feature_extractor\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"The 'feature_extractor' argument is deprecated. Use 'image_processor' instead.\",\n",
    "                FutureWarning,\n",
    "            )\n",
    "            feature_extractor = kwargs.pop(\"feature_extractor\")\n",
    "\n",
    "        # Set the image processor and tokenizer\n",
    "        image_processor = image_processor if image_processor is not None else feature_extractor\n",
    "        if image_processor is None or tokenizer is None:\n",
    "            raise ValueError(\"Both 'image_processor' and 'tokenizer' must be specified.\")\n",
    "\n",
    "        # Initialize the processor mixin\n",
    "        super().__init__(image_processor, tokenizer)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        # Process either images or text based on input\n",
    "        images = kwargs.pop(\"images\", None)\n",
    "        text = kwargs.pop(\"text\", None)\n",
    "\n",
    "        if images is not None:\n",
    "            return self.image_processor(images, *args, **kwargs)  # Process images\n",
    "        elif text is not None:\n",
    "            return self.tokenizer(text, **kwargs)  # Process text\n",
    "        else:\n",
    "            raise ValueError(\"Either 'images' or 'text' input must be provided.\")\n",
    "\n",
    "    def batch_decode(self, *args, **kwargs):\n",
    "        return self.tokenizer.batch_decode(*args, **kwargs)  # Batch decode tokens\n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        return self.tokenizer.decode(*args, **kwargs)  # Decode tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8809ba-6c58-48b2-9196-5c807ab8028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(\n",
    "    'microsoft/swin-base-patch4-window12-384-in22k'\n",
    ")\n",
    "tokenizer = MBartTokenizer.from_pretrained(\n",
    "    'facebook/mbart-large-50'\n",
    ")\n",
    "processor = CustomOCRProcessor(image_processor,tokenizer)\n",
    "train_dataset = MedicalDataset(root_dir=data_path,\n",
    "                           df=df_train,\n",
    "                           processor=processor,max_target_length=55)\n",
    "eval_dataset = MedicalDataset(root_dir=data_path,\n",
    "                           df=df_test,\n",
    "                           processor=processor,max_target_length=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db4df0-ecb8-44ba-99d1-77e91bc3a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, Trainer, TrainingArguments\n",
    "\n",
    "# Load the pre-trained model and processor\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-handwritten\") \n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-handwritten\")\n",
    "\n",
    "\n",
    "# Define a function to preprocess the images and texts\n",
    "def preprocess_data(data):\n",
    "    images = []\n",
    "    texts = []\n",
    "    for index, row in data.iterrows():\n",
    "        image_path = os.path.join(\"C:/Users/mahad/Desktop/fyp2/data/train\", row[\"FILENAME\"])\n",
    "        text = row[\"IDENTITY\"]\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        images.append(img)\n",
    "        texts.append(text)\n",
    "    return images, texts\n",
    "\n",
    "train_images, train_texts = preprocess_data(df_train)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./trocr_fine_tuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Define Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=list(zip(train_images, train_texts)),\n",
    "    # Add any other necessary arguments such as eval_dataset, data_collator, etc.\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model (optional)\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
